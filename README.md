# AutoLRS 

This is the PyTorch code implementation for the paper [_AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly_](https://openreview.net/forum?id=SlrqM9_lyju) published at ICLR 2021.

A TensorFlow version will appear in this repo later.

## What is AutoLRS?
Finding a good learning rate schedule for a DNN model is non-trivial. The goal of AutoLRS is to automatically tune the learning rate (LR) over the course of training without human involvement. AutoLRS chops up the whole training process into a few training stages (each consists of τ steps), and its mission is to determine a constant LR for each training stage. AutoLRS treats the validation loss as a black-box function of LR, and uses Bayesian optimization (BO) to search for the best LR which can minimize the validation loss for each training stage. Because BO would require τ steps of training to evaluate the validation loss for each LR it explores, to reduce this cost, we only apply an LR to train the DNN for τ’ (τ’ << τ) steps and train an exponential time-series forecasting model to predict the loss after τ steps. In our default setting, τ’ = τ/10 and BO explores 10 LRs in each stage, so it strikes a nice balance between the steps invested in search and the steps used for actual training, and makes AutoLRS practical to use.

AutoLRS does not depend on a pre-defined LR schedule, dataset, or a specified task and is compatible with almost all optimizers. The LR schedules auto-generated by AutoLRS lead to speedup over highly hand-tuned LR schedules for several state-of-the-art DNNs including ResNet-50, Transformer, and BERT.

## Setup
```sh
$ pip install --user -r requirements.txt
```
## How to use AutoLRS for your work?
`autolrs_server.py` is the brain of AutoLRS, which implements the search algorithm including BO and the exponential forecasting model.

`autolrs_callback.py` implements a callback which you can plug into your Pytorch training loop. The callback receives commands from the server via socket, adjusting the learning rate, saving/restoring model parameters and optimizer states according to commands sent from the server.

## Example
We provide an example of using AutoLRS to train various DNNs on the CIFAR-10 dataset. The models are imported from `kuangliu`'s great and simple [pytorch-cifar](https://github.com/kuangliu/pytorch-cifar) repository.

__Prerequisites:__ 
Python 3.6+, PyTorch 1.0+

__Run the example__ 
```sh
$ bash run.sh
```

## Contact 
+ [Yuchen Jin](https://homes.cs.washington.edu/~yuchenj)

You can contact us at <yuchenj@cs.washington.edu>. We would love to hear your questions and feedback!

## Poster
<img src="poster.png" width="800px"/>
